{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f199ab1-773f-4cf4-a22c-23788e6ceaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: This code plots Figure 3 of the manuscript.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#fig, ax = plt.subplots()\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from math import pi\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import r2_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "torch.manual_seed(123456)\n",
    "np.random.seed(123456)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "class Unit3(nn.Module):\n",
    "    def __init__(self, in_N, out_N,actf):\n",
    "        super(Unit3, self).__init__()\n",
    "        self.in_N = in_N\n",
    "        self.out_N = out_N\n",
    "        self.actf = actf\n",
    "        self.L = nn.Linear(in_N, out_N)\n",
    "\n",
    "    def forward(self, x):\n",
    "        actf=self.actf\n",
    "        x1 = self.L(x)\n",
    "        if actf==0:\n",
    "            x2 = torch.tanh(x1)\n",
    "        elif actf==1:\n",
    "            x2 = torch.sigmoid(x1) \n",
    "        elif actf==2:\n",
    "            x2 = torch.relu(x1)\n",
    "        elif actf==3:\n",
    "            x2 = torch.selu(x1)\n",
    "        elif actf==4:\n",
    "            x2 = F.softmax(x1, dim=1)\n",
    "        return x2\n",
    "    \n",
    "class NN3(nn.Module):\n",
    "    def __init__(self, in_N, width1, depth1,width2, depth2,out_N,bn,dp,dprate,actf):\n",
    "        super(NN3, self).__init__()\n",
    "        self.width1 = width1\n",
    "        self.width2 = width2\n",
    "        self.depth1 = depth1\n",
    "        self.depth2 = depth2\n",
    "        self.bn = bn\n",
    "        self.dp = dp\n",
    "        self.dprate = dprate\n",
    "        self.actf = actf\n",
    "        self.in_N = in_N\n",
    "        self.out_N = out_N\n",
    "        self.stack = nn.ModuleList()\n",
    "        self.stack.append(Unit3(in_N, width1[0],actf))\n",
    "        if bn==1:\n",
    "            self.stack.append(nn.BatchNorm1d(width1[0]))\n",
    "        for i in range(1,depth1):\n",
    "            self.stack.append(Unit3(width1[i-1], width1[i],actf))\n",
    "        \n",
    "        if dp==1:\n",
    "            self.stack.append(nn.Dropout(p=dprate))\n",
    "        if depth2==1:\n",
    "            self.stack.append(Unit3(width1[i], width2[0],1)) \n",
    "        else:\n",
    "            self.stack.append(Unit3(width1[i], width2[0],actf))    \n",
    "            for i in range(1,depth2-1):\n",
    "                self.stack.append(Unit3(width2[i-1], width2[i],actf))\n",
    "            self.stack.append(Unit3(width2[depth2-2], width2[depth2-1],4)) \n",
    "            \n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.stack)):\n",
    "            x = self.stack[i](x)\n",
    "        return x\n",
    "\n",
    "activation=0\n",
    "dropout=1\n",
    "dropout_rate=0.29791\n",
    "normalization=1\n",
    "batch_size=1000\n",
    "layers1=10\n",
    "layers2=1\n",
    "neurons=86\n",
    "learning_rate=0.00065\n",
    "L1=[neurons]*layers1\n",
    "L2=[neurons]*layers2+[8]\n",
    "model_h = NN3(35,L1,layers1,L2,layers2+1, 8,normalization,dropout,dropout_rate,0)\n",
    "\n",
    "\n",
    "        \n",
    "load=1\n",
    "PATH=\"checkpoint/model-1406.pt\"\n",
    "if load==1:\n",
    "    checkpoint = torch.load(PATH)\n",
    "    model_h.load_state_dict(checkpoint['model_h_state_dict'])\n",
    "    optimizer2 = optim.AdamW([{'params': model_h.parameters()}], lr=learning_rate) \n",
    "    optimizer2.load_state_dict(checkpoint['optimizer2_state_dict'])\n",
    "    \n",
    "model_h.eval()\n",
    "xlo_test=np.load('xlo_test.npy')\n",
    "ylo_test=np.load('ylo_test.npy')\n",
    "pred_2h_star_test = model_h(torch.from_numpy(xlo_test).float())\n",
    "\n",
    "r2_test0 = r2_score(ylo_test[:,0], pred_2h_star_test.detach().numpy()[:,0])\n",
    "r2_test1 = r2_score(ylo_test[:,1], pred_2h_star_test.detach().numpy()[:,1])\n",
    "r2_test2 = r2_score(ylo_test[:,2], pred_2h_star_test.detach().numpy()[:,2])\n",
    "r2_test3 = r2_score(ylo_test[:,3], pred_2h_star_test.detach().numpy()[:,3])\n",
    "r2_test4 = r2_score(ylo_test[:,4], pred_2h_star_test.detach().numpy()[:,4])\n",
    "r2_test5 = r2_score(ylo_test[:,5], pred_2h_star_test.detach().numpy()[:,5])\n",
    "r2_test6 = r2_score(ylo_test[:,6], pred_2h_star_test.detach().numpy()[:,6])\n",
    "r2_test7 = r2_score(ylo_test[:,7], pred_2h_star_test.detach().numpy()[:,7])\n",
    "r2_test_final=np.hstack([r2_test0,r2_test1,r2_test2,r2_test3,r2_test4,r2_test5,r2_test6,r2_test7])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x=np.arange(0,1,0.01)    \n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8), tight_layout=True)\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        ax = axes[i, j]\n",
    "        ax.scatter(ylo_test[:, i * 4 + j], pred_2h_star_test.detach().numpy()[:, i * 4 + j], color='black', alpha=0.1)\n",
    "        ax.plot(x, x, color='red')\n",
    "        ax.set_xlabel('True label',fontsize=25, fontname='Times New Roman')\n",
    "        ax.set_ylabel('Predicted label',fontsize=25, fontname='Times New Roman')\n",
    "        ax.set_aspect('equal')  \n",
    "        tick_values = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        ax.set_xticks(tick_values)\n",
    "        ax.set_xticklabels(tick_values, fontsize=25, fontname='Times New Roman')\n",
    "        ax.set_yticks(tick_values)\n",
    "        ax.set_yticklabels(tick_values, fontsize=25, fontname='Times New Roman')\n",
    "        \n",
    "plt.savefig('figure.png', dpi=600)\n",
    "print('R2 of all phases are as follows respecitvely:',r2_test_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASharghEnv",
   "language": "python",
   "name": "asharghenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
