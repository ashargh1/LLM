{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95074e6-9827-43cf-b0a9-dcdc6ef44593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: This code is used to plot Figure 5(b-d) of the manscuript.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#fig, ax = plt.subplots()\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from math import pi\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import r2_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "torch.manual_seed(123456)\n",
    "np.random.seed(123456)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "\n",
    "class Unit3(nn.Module):\n",
    "    def __init__(self, in_N, out_N,actf):\n",
    "        super(Unit3, self).__init__()\n",
    "        self.in_N = in_N\n",
    "        self.out_N = out_N\n",
    "        self.actf = actf\n",
    "        self.L = nn.Linear(in_N, out_N)\n",
    "\n",
    "    def forward(self, x):\n",
    "        actf=self.actf\n",
    "        x1 = self.L(x)\n",
    "        if actf==0:\n",
    "            x2 = torch.tanh(x1)\n",
    "        elif actf==1:\n",
    "            x2 = torch.sigmoid(x1) \n",
    "        elif actf==2:\n",
    "            x2 = torch.relu(x1)\n",
    "        elif actf==3:\n",
    "            x2 = torch.selu(x1)\n",
    "        elif actf==4:\n",
    "            x2 = F.softmax(x1, dim=1)\n",
    "        return x2\n",
    "    \n",
    "class NN3(nn.Module):\n",
    "    def __init__(self, in_N, width1, depth1,width2, depth2,out_N,bn,dp,dprate,actf):\n",
    "        super(NN3, self).__init__()\n",
    "        self.width1 = width1\n",
    "        self.width2 = width2\n",
    "        self.depth1 = depth1\n",
    "        self.depth2 = depth2\n",
    "        self.bn = bn\n",
    "        self.dp = dp\n",
    "        self.dprate = dprate\n",
    "        self.actf = actf\n",
    "        self.in_N = in_N\n",
    "        self.out_N = out_N\n",
    "        self.stack = nn.ModuleList()\n",
    "        self.stack.append(Unit3(in_N, width1[0],actf))\n",
    "        if bn==1:\n",
    "            self.stack.append(nn.BatchNorm1d(width1[0]))\n",
    "        for i in range(1,depth1):\n",
    "            self.stack.append(Unit3(width1[i-1], width1[i],actf))\n",
    "        \n",
    "        if dp==1:\n",
    "            self.stack.append(nn.Dropout(p=dprate))\n",
    "        if depth2==1:\n",
    "            self.stack.append(Unit3(width1[i], width2[0],1)) \n",
    "        else:\n",
    "            self.stack.append(Unit3(width1[i], width2[0],actf))    \n",
    "            for i in range(1,depth2-1):\n",
    "                self.stack.append(Unit3(width2[i-1], width2[i],actf))\n",
    "            self.stack.append(Unit3(width2[depth2-2], width2[depth2-1],4)) \n",
    "            \n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.stack)):\n",
    "            x = self.stack[i](x)\n",
    "        return x\n",
    "\n",
    "activation=0\n",
    "dropout=1\n",
    "dropout_rate=0.29791\n",
    "normalization=1\n",
    "batch_size=1000\n",
    "layers1=10\n",
    "layers2=1\n",
    "neurons=86\n",
    "learning_rate=0.00065\n",
    "L1=[neurons]*layers1\n",
    "L2=[neurons]*layers2+[8]\n",
    "model_h = NN3(35,L1,layers1,L2,layers2+1, 8,normalization,dropout,dropout_rate,0)\n",
    "\n",
    "\n",
    "        \n",
    "load=1\n",
    "PATH=\"checkpoint/model-1406.pt\"\n",
    "if load==1:\n",
    "    checkpoint = torch.load(PATH)\n",
    "    model_h.load_state_dict(checkpoint['model_h_state_dict'])\n",
    "    optimizer2 = optim.AdamW([{'params': model_h.parameters()}], lr=learning_rate) \n",
    "    optimizer2.load_state_dict(checkpoint['optimizer2_state_dict'])\n",
    "\n",
    "import numpy as np\n",
    "norm=np.load('norm.npy')[0]\n",
    "norm[10,1]=1\n",
    "norm[11,1]=1\n",
    "norm[12,1]=1\n",
    "norm[13,1]=1\n",
    "norm[14,1]=1\n",
    "norm[15,1]=1\n",
    "\n",
    "Temp=1200 #temperature\n",
    "A = np.loadtxt(f'Labels_7el_d=0.03_{Temp}K_extra.txt')[:, 10:]\n",
    "comp=np.loadtxt(f'Labels_7el_d=0.03_{Temp}K_extra.txt')[:,1:8]\n",
    "a=Temp*np.ones([A.shape[0],1])\n",
    "A=np.append(A,a,axis=1)\n",
    "\n",
    "for i in range(A.shape[0]):\n",
    "    for j in range(A.shape[1]):\n",
    "        A[i,j]=(A[i,j]-norm[j][0])/(norm[j][1]-norm[j][0])\n",
    "        \n",
    "n=[7,9,38,40,45,48,49,39,25,26,29,47,34,35,41,46]\n",
    "A1=np.delete(A,n,axis=1)\n",
    "model_h.eval()\n",
    "xlo_test=A1\n",
    "y = model_h(torch.from_numpy(xlo_test).float())\n",
    "n=np.zeros([0,7])\n",
    "for i in range(y.shape[0]):\n",
    "    a=y[i,0]+y[i,2]+y[i,3]+y[i,4]+y[i,5]+y[i,6]+y[i,7]\n",
    "    if a<0.10: #threshold of phase\n",
    "        n=np.append(n,comp[[i],:],axis=0)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "num_labels = 7\n",
    "num_points = n.shape[0]\n",
    "print('num_points=',num_points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASharghEnv",
   "language": "python",
   "name": "asharghenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
